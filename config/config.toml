[env]
project_name = "Polymorphic Data Reporter"
timezone = "America/Chicago"
seed = 42
theme = "dark_blue"

[storage.local]
enabled = true
raw_root = "data/raw"
gold_root = "data/gold"

[storage.minio]
enabled = true
endpoint = "http://minio:9000"
access_key = "admin"
secret_key = "admin"
secure = false
bucket = "datasets"
raw_prefix = "raw/"
gold_prefix = "gold/"

[auth]
# If Airflow UI or any optional service needs creds in-app
username = "admin"
password = "admin"

[sources]
# discover from both local and MinIO
locations = [
  "file://data/raw/sales_demo",
  "s3://datasets/raw/iot_sensors/"
]

[duckdb]
persist = true  # physical .duckdb written under data/gold/<slug>/tables/

[profiling.roles]
cat_cardinality_max = 120
datetime_formats = ["%Y-%m-%d", "%m/%d/%Y", "%Y-%m-%d %H:%M:%S"]

[profiling.outliers]
method = "zscore"         # zscore | iqr
zscore_threshold = 3.0
iqr_multiplier = 1.5

# ---------- NLP / NLG ----------

[nlp]
sample_rows = 20000
min_schema_confidence = 0.90
min_role_confidence = 0.90
max_iter = 1000
min_improvement = 0.0
enable_domain_templates = true
granularity = "slug"  # slug | subdir | file

[nlp.role_scoring]
name_weight = 0.45
value_weight = 0.55

# thresholds
bool_token_min_ratio = 0.57     # share of values that look boolean
date_parse_min_ratio = 0.60     # share of values that parse as dates
unique_id_ratio = 0.95          # uniqueness ratio to consider "id-ish"
categorical_max_unique_ratio = 0.02
text_min_avg_len = 8            # avg string length to lean "text" vs "categorical"
min_non_null_ratio = 0.10       # ignore columns with less data than this

# bonuses/penalties
bonus_id_name = 0.10            # extra if name strongly looks like id (e.g., *_id)
penalize_bool_for_many_tokens = 0.08  # slight penalty if too many distinct tokens for bool

[nlg.constants]
inventory_key = "_inventory"
narrative_filename = "narrative.txt"

# ---------- Dynamic Cleaning Policy (highly flexible) ----------

[cleaning.columns]
drop_missing_pct = 0.90
min_unique_ratio = 0.001
always_keep = ["id", "date", "timestamp"]
cat_cardinality_max = 200           # enforce category dtype under this

[cleaning.normalize]
strip_text = true
lowercase_text = false
standardize_dates = true
enforce_categorical = true

[cleaning.impute]
numeric_default = "median"          # mean|median|ffill|bfill|interpolate
categorical_default = "Unknown"
text_default = "N/A"
time_aware_interpolation = true

[cleaning.outliers]
detect = "zscore"                   # zscore|iqr
zscore_threshold = 3.0
iqr_multiplier = 1.5
handle = "flag"                     # flag|winsorize|drop
winsor_limits = [0.01, 0.99]

# Rulepacks: ordered lists of conditional rules (mini DSL)
# Builtins are loaded automatically; you can add/override here.
[cleaning.normalize_null_tokens]
null_tokens = ["", "NA", "N/A", "N\\A", "None", "NULL", "NaN", "-", "—", "<NA>", "<Null>", "<None>", "nil", "missing"]

[[cleaning.rules]]
id = "normalize-nulls-first"
priority = 120
when = 'type == "string"'
then = 'normalize_null_tokens(null_tokens=cleaning.normalize_null_tokens.null_tokens, case_insensitive=true)'

[[cleaning.rules]]
id = "coerce-numeric"
priority = 100
when = 'role == "numeric" and type == "string"'
then = 'coerce_numeric()'

[[cleaning.rules]]
id = "coerce-numeric-from-string-heuristic"
priority = 90
when = 'type == "string" and role != "time" and avg_len <= 24 and missing_pct < 0.99'
then = 'coerce_numeric()'

[[cleaning.rules]]
id = "impute-numeric-any"
priority = 95
when = 'missing_pct > 0 and (type in ["int","float"] or role in ["numeric","id"])'
then = 'impute(numeric_default)'

[[cleaning.rules]]
id = "impute-numeric-time"
priority = 92
when = 'role == "numeric" and missing_pct > 0 and has_time_index'
then = 'impute("interpolate")'

[[cleaning.rules]]
id = "impute-numeric-default"
priority = 80
when = 'role == "numeric" and missing_pct > 0'
then = 'impute(numeric_default)'

[[cleaning.rules]]
id = "impute-categorical"
priority = 80
when = 'role == "categorical" and type == "string" and missing_pct > 0'
then = 'impute_value(categorical_default)'

[[cleaning.rules]]
id = "impute-text"
priority = 55
when = 'role == "text" and type == "string" and missing_pct > 0 and avg_len >= 8'
then = 'impute_value(text_default)'

[[cleaning.rules]]
id = "flag-outliers"
priority = 70
when = 'role == "numeric"'
then = 'outliers(detect, zscore_threshold, iqr_multiplier, handle, winsor_limits)'

[[cleaning.rules]]
id = "normalize-text"
priority = 50
when = 'role == "text" and type == "string"'
then = 'text_normalize(strip=cleaning.normalize.strip_text, lower=cleaning.normalize.lowercase_text)'

[[cleaning.rules]]
id = "enforce-categorical"
priority = 50
when = 'role == "categorical" and type == "string" and cardinality <= cleaning.columns.cat_cardinality_max'
then = 'cast_category()'

[[cleaning.rules]]
id = "ensure-text-string-dtype"
priority = 49
when = 'role == "text"'
then = 'cast_string()'

[[cleaning.rules]]
id = "impute-time-forward"
priority = 100
when = 'role == "time" and missing_pct > 0 and has_time_index'
then = 'impute_dt("ffill")'

# Otherwise median as a fallback
[[cleaning.rules]]
id = "impute-time-default"
priority = 95
when = 'role == "time" and missing_pct > 0 and not has_time_index'
then = 'impute_dt("median")'

[[cleaning.rules]]
id = "impute-time-median"
priority = 80
when = 'role == "time" and missing_pct > 0'
then = 'impute_dt("median")'

[[cleaning.rules]]
id = "materialize-missing-text-literal"
priority = 44
when = 'type == "string" and missing_pct > 0'
then = 'materialize_missing_as(cleaning.impute.text_default)'

[[cleaning.rules]]
id = "final-null-guard-text"
priority = 46  # runs after your other imputations (50+), before drops (40)
when = 'type == "string" and missing_pct > 0'
then = 'impute_value(text_default)'

[[cleaning.rules]]
id = "normalize-nulls-last"
priority = 45
when = 'type == "string"'
then = 'normalize_null_tokens(null_tokens=cleaning.normalize_null_tokens.null_tokens, case_insensitive=true, apply_text_normalize_first=false)'

[[cleaning.rules]]
id = "drop-sparse"
priority = 40
when = 'missing_pct >= cleaning.columns.drop_missing_pct and name notin cleaning.columns.always_keep'
then = 'drop_column()'

[[cleaning.rules]]
id = "drop-constant"
priority = 40
when = 'unique_ratio <= cleaning.columns.min_unique_ratio and name notin cleaning.columns.always_keep'
then = 'drop_column()'

[[cleaning.rules]]
id = "parse-datetime-by-name-heuristic"
priority = 130
when = 'type == "string" and (icontains(name,"date") or icontains(name,"time") or icontains(name,"dt_"))'
then = 'parse_datetime(datetime_formats)'

[[cleaning.rules]]
id = "parse-datetime"
priority = 120
when = 'role == "time" and type == "string"'
then = 'parse_datetime(datetime_formats)'

[[cleaning.rules]]
id = "parse-datetime-from-numeric"
priority = 118
when = 'role == "time" and type in ["int","float"]'
then = 'parse_epoch()'   # auto-detects ns/ms/s

# ---------- Topic Selection & Charts ----------

[topics.thresholds]
min_corr_for_scatter = 0.35
min_slope_for_trend = 0.02
max_categories_bar = 20
max_series_line = 8
max_charts_total = 12

[charts]
max_charts_per_topic = 6
facet_max_series = 8
topk_categories = 20
prefer_small_multiples = true
allow_pie_when_n_le = 5
enable_advanced = ["treemap","sankey","calendar_heatmap","parcoords"]
export_static_png = true

[weights]
suitability = 3.0
effect_size = 2.5
signal_quality = 2.0
readability = 1.5
complexity = 1.0

# ---------- Output & Orchestration ----------

[reports.enabled_generators]
csv = true
json = true
parquet = true
charts = true
html = true
pdf = true

[reports.html]
template = "base.html"
title_prefix = "Report:"
embed_interactive = true

[reports.pdf]
engine = "chromium"          # chromium
page_size = "Letter"
margins = "0.5in"

[airflow]
dag_id = "polymorphic_report_dag"
schedule = "0 2 * * *"
max_active_runs = 1
catchup = false
concurrency = 8
task_retries = 2
username = "admin"
password = "admin"

[docker]
compose_file = "docker/docker-compose.yml"
airflow_image = "local/airflow:latest"
chrome_image = "local/chrome:latest"

[logging]
level = "INFO"
structured_json = true

[publishing]
enabled = false
target = "s3://datasets/gold-exports/"
access_key = "admin"
secret_key = "admin"
